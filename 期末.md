![image-20220603164543232](期末.assets/image-20220603164543232.png)



# 2.General Sys Design

机器学习三个要素： T E P

Task  Experience  Performance



系统设计：

1. 用于训练的经验。 注意训练数据偏差
2. 应该学什么。 定义**目标函数**。注意正确性和可行性。为了可行性，这里可以有近似/假设 ~  作为评估。比如评估函数$V$的近似$\hat V$。
3. 假设的表示。好的近似，注意对数据的要求。
4. 学习算法。综合特征和学习目标选择。比如Least MSE $\sum_{training\ set} (V_{train}(b) - \hat V (b))^2$

即：数据 特征 表示 算法 评价



- 实例空间X（属性描述）  
- 假设空间H（比如我们根据属性，做出的决策树，if xxx then do xxx）  
- 训练样例空间D  
- 目标概念C 
- 训练集中的样本形如$<x_i,c(x_i)>$

我们要做的事情可以描述为 求一个假设$h\in H$，满足$h(x)=c(x) \ for \ all\  x \in X$



如果有n个属性，那么实例空间就有$2^n$个元素（每个属性yes or no），假设空间至多$2^{2^n}$个元素（顶多每个实例都在假设中作为正例or负例出现）



# 3.Decision Tree

找下一步最佳决策属性（为了使决策树尽量简洁，occam‘s razor），派生出来的节点数据尽量纯（分得尽量开），减小混杂度（即熵）

## ID3

熵Entropy:
$$
Entropy(N) = - \sum_j P(w_j) \log_2 P(w_j)
$$
选择最佳决策属性的时候，要找最大化**信息增益**的属性：
$$
Gain(S,A) = Entropy(S) - \sum_{v\in Values(A)} {|S_v|\over |S|} Entropy(S_v)
$$
S是样本（包括正例和负例）。 信息增益 = 原始S的熵值 - 经过属性A分类以后的期望熵值（两个子节点熵的加权平均）



停止（完美分类）的判断：子集输入全相同 或者 输出全相同



算的是局部最优



## 过拟合

$h \in H$过拟合的定义：存在另一个假设$h'\in H$，使得$err_{train}(h) < err_{train}(h')$，并且$err_{test}(h) > err_{test}(h')$。（h'训练集上更劣，但测试集上更优）



应对过拟合：预剪枝（一个节点的训练样本数太少的时候，or基于信息增益的阈值），后剪枝（错误降低剪枝：如果剪掉可以提高验证集准确度，就剪掉；和规则后剪枝）

规则后剪枝：将树转换为若干条等价的规则集合；考虑每条规则，去掉一些规则前件来提高该规则准确率；按准确率从高到低对所有规则排序；predict的时候，依次查看是否满足每条规则



如果一个叶子节点子集有多个输入，那么可以该叶子节点赋值成最常见的label。



当ID3某一属性取值太多了，他更容易被优先选择，可以用信息增益比代替信息增益，信息增益比就是信息增益除以S在A的熵。



# 4.Bayesian

归纳学习假设：任一假设若在足够大的训练样例集中很好地逼近目标函数，它也能在未见实例中很好地逼近目标函数  



贝叶斯定理：用先验概率推断后验概率
$$
P(h|D) = {P(D|h) P(h) \over P(D)}
$$
h是得癌症，D是化验结果为阳性。P(h)是h的先验概率。P(D)是D的先验概率，要与h相互独立。

$P(h|D)$是h的后验概率。

$P(D|h)$是似然度likelihood。常常用对数似然 $\log(P(D|h))$



## MAP

Maximum A Posteriori (MAP): (极大后验假设)  ：给定训练集，因此$P(D)$固定
$$
h_{MAP}=\arg\max_{h\in H} P(h|D) = \arg\max_{h\in H}{P(D|h) P(h) \over P(D)}=\arg\max_{h\in H} P(D|h) P(h)
$$
根据$P(D|h) P(h)$来选择最大值



## ML

Maximum Likelihood, ML, 极大似然假设

MAP里面$h_{MAP}=\arg\max_{h\in H} P(D|h) P(h)$ ，如果完全不知道假设h的概率分布（假设h的概率分布P(h)是均匀的），那么有极大似然假设：
$$
h_{ML} = \arg \max_{h_i\in H} P(D|h_i)
$$


极大似然&最小二乘是有联系的，独立随机变量，正态分布噪声$N(0,\sigma^2)$的条件下$h_{ML}=h_{LSE}$。



## 朴素贝叶斯NB

每个属性独立

目标函数$f: X\rightarrow V$，每个样本$x=(a_1,\dots,a_n)$，那么最有可能的$f(x)$值是：
$$
v_{MAP} = \arg\max_{v_j\in V} P(x|v_j) P(v_j)
$$
假设每个属性独立，那么$P(x|v_j ) = P(a_1, \dots a_n | v_j) = \prod_i P(a_i|v_j)$

So:
$$
v_{NB} = \arg\max_{v_j \in V} P(v_j) \prod_i P(a_i|v_j) = \arg\max_{v_j \in V} (\log P(v_j) +\sum_i \log P(a_i|v_j))
$$


# 5.IBL

Instance-based Learning  

之前的模型都是这样的方法：估计问题特性；作出模型假设；找到最优参数

IBL的动机就是：人类回忆、类比来推理



参数化与非参数化：

参数化：设定一个函数形式，简单，但可能存在很大的偏置（实际不符合假设）。比如RL的Q-function

非参数化：分布和密度的估计是data-driven的，不需要事先对函数形式作估计



IBL无需构建模型，只需存储所有训练样例，需要predict的时候才开始处理



## 最近邻，k近邻

相似度--距离函数，找训练样例中相似度最高的

1-NN 的错误率不大于 Bayes 方法错误率的 2 倍  



KNN：找最近的K个点，进行投票

每个属性值范围不一样，所以要进行归一化，归一化到[0,1]。

还要在计算距离时，对每个属性之差进行加权，再加和

效率方面：使用KD-tree。

需要找一个合适的距离函数。另外，不相关的特征 对距离的度量有负面的影响 。



## 距离加权KNN

每个邻居的贡献不一样，考虑对数据加权，更接近的邻居赋予更大的权重。
$$
w_i = K(d(x_i,x_q))
$$
$x_q$是待查询点。K是核函数，与距离成反比，常用的核函数有$1/d^2, e^{-d}, 1/(1+d), e^{-(d/\sigma)^2}$。这里$\sigma$是核宽度$K_w$

输出是加权平均： ${ \sum w_i y_i\over \sum w_i}$  （难道这里指的是回归问题，label是连续的值???） 我的理解是，$w_i$不就是权函数吗，投票的时候算权重



# 6.Unsupervised Learning

积极学习：训一个模型，假设。训练时间长，测试时间短。倾向于给出全局估计。

懒惰学习：基于实例的学习。可以给出局部估计。



相比有标注的有监督学习关注条件分布$P(Y|X)$，无监督学习关注联合分布$P(X)$

半监督学习则是通过少量的有标注数据和很多无标注数据来学习条件分布$P(Y|X)$



无监督学习主要在于发现无标注数据的结构、输入的合理表示等



## 聚类

好的聚类：类内距离小 类间距离大



软聚类：同一对象可以属于多个类

硬聚类：同一对象只能属于一个类



层次聚类 vs. 非层次聚类
层次： 一个所有类间的层次结构（tree）
非层次： 平的，只有一层  



聚类也需要衡量对象间的距离（相似度）。对于非数值数据，可以采用相似度矩阵。数值数据可以直接用某种距离计算。



## K-means

1. 随机选K个种子，作为类中心，使得$d(g_i,g_j)>d_{min}$
2. 根据最近距离把各个点分配给各个类
3. 计算新的类中心（直接每个类取点均值），然后重复2-3步

通过迭代的方法聚类，不一定能找到最优解。是硬聚类、非层次



对噪声和离群点敏感



## K-medoids

在上面的第3步中，不用类均值，而用最靠近类中心的点。

当存在噪音和孤立点时, K-medoids 比 K-means 更鲁棒。K-medoids 对于小数据集工作得很好, 但不能很好地用于大数据集  



而PAM则是在第3步中，随机用一个非中心对象替换类中心，类的质量提高了就保留。



衡量好坏/取最靠近类中心的点都用的是代价函数，即类内对象与类中心的平均不相似度  



# 7.Hypo eval

K-means的形式化：
$$
\min\ J={1 \over N} \sum_{n=1}^N \sum_{v=1}^K r_{nv} ||u_n - g_v||^2
$$
N个点，K个类，$r_{nv}$是one-hot向量，表示每个点是否在各个类中，$u_n$是每个点，$g_v$是每个类中心。

可以通过轮流更新的方法来最小化。1.固定$g_v$优化$r_{nv}$。 2.固定$r_{nv}$优化$g_v$。实际上和之前K-means的步骤是一样的。



## 凝聚式层次聚类算法  

一开始每个点单独属于一个类，然后不断将最相似的两个类合并，直至最后剩下k个类。



类之间的相似度可以用 （最近点对、最远点对、距离平均值）来衡量



这样凝聚的过程可以看作是一棵树。



## 机器学习理论



### 假设评估

真实误分类的概率：$error_D(h)=p$，现在考虑测试的时候，n个随机样本，有r个被误分类这个事件。

测试集~S，误分类$error_S(h) = {r \over n}$

r个被误分类，r这个随机变量的分布是个二项分布。
$$
E[r] = np, \quad E[error_S(h)]=np/n=p, \\
\sigma_{error_S(h)}={\sigma_r \over n} = {\sqrt{np(1-p)} \over n} = \sqrt{error_D(h)(1-error_D(h))\over n} \approx \sqrt{error_S(h)(1-error_S(h))\over n}
$$


我现在是拿测试集上的误分类率$error_S(h)$来估计真实的误分类率$error_D(h)$

估计的bias： 
$$
bias = E[error_S(h)] - error_D(h)
$$
如果S是训练集，那结果是有偏的（偏乐观，因为训练集上面的误分类概率更小），所以不要在训练集上面做测试



即使是无偏估计，$error_S(h)$和$error_D(h)$也有可能不一样，因为只是期望一样，另外还有方差的存在。

需要选择无偏且有最小方差的估计



# 8.Hypo eval II

足够大的样本集合，二项分布可以很好地近似正态分布



## errorS的分布

考虑95%置信区间，有95%的概率$error_S(h)$落在区间$error_D(h) \pm z_N\sqrt{error_D(h)(1-error_D(h))\over n}$。  注意这里是用S来估计D，D是无偏估计下S的期望。

$z_N=1.96$ (95%)



等价于$error_D(h)$落在区间$error_S(h) \pm z_N\sqrt{error_D(h)(1-error_D(h))\over n}$

近似等于$error_S(h) \pm z_N\sqrt{error_S(h)(1-error_S(h))\over n}$



<img src="期末.assets/image-20220604153553996.png" alt="image-20220604153553996" style="zoom: 33%;" />



为了确定Y的分布D，可以考虑中心极限定理：IID的随机变量$Y_1,\dots,Y_n$，那么$\hat Y = {1\over N} \sum_{i=1}^N Y_i$ 服从正态分布$N(\mu, \sigma^2/n)$



## 假设间的错误率差异

### z检验

现在想比较两个假设h1和h2的错误率差异。

在样本集合$S_1$上测试$h_1$，在样本集合$S_2$上测试$h_2$

要估计的参数便是$d=error_D(h_1) - error_D(h_2)$

选择无偏估计量 $\hat d = error_{S_1}(h_1) - error_{S_2}(h_2)$， 两项都服从正态分布，$\hat d$也近似正态分布，均值为$d$，方差为两个方差的和
$$
\sigma_{\hat d } = \sqrt{{error_{S_1}(h_1)(1-error_{S_1}(h_1))\over n_1} + {error_{S_2}(h_2)(1-error_{S_2}(h_2))\over n_2}}
$$
$\hat d$有$N\%$的概率落在$d \pm z_N \sigma_{\hat d}$区间，也可以反过来想d的区间...



一般是给定$\hat d$，问$d>0$的概率，那么就是$\hat d$落在$\hat d < d + 0.1 = \mu_{\hat d } + 0.1 = \mu_{\hat d } + \sigma_{\hat d }* {0.1 \over \sigma_{\hat d }} = \mu_{\hat d } + \sigma_{\hat d }* z_N$的概率，可以算出$z_N$进而推出概率，注意这里是单边置信区间，要转换概率为单边。



### t检验

考虑k折交叉验证，有训练集和测试集同时存在。

$L(S_0)$表示使用学习算法$L$在训练集$S_0$ 上进行训练得到的假设

$error_{T_0}(L_A(S_0))$里面的$T_0$便是测试集



k折交叉验证：在同一个子集上对比A和B算法
$$
i=1,\dots k\\
h_A \leftarrow L_A(S_i) \\
h_B \leftarrow L_B(S_i) \\
\delta_i = error_{T_i}(h_A)  - error_{T_i}(h_B)
$$
为了比较两算法，考虑$\bar \delta = {1\over k }\sum_{i=1}^k\delta_i$

那么对d的N%置信区间估计就是$\bar \delta\pm t_{N,k-1} s_{\bar \delta}$

其中$s_{\bar \delta} = \sqrt{{1\over k(k-1)} \sum_{i=1}^k (\delta_i - \bar \delta)^2}$

